## Python Study 

## íŒŒì´ì¬ ìŠ¤í„°ë”” 1ì¼ì°¨

|ë‚ ì§œ|ì œëª©|ì„¤ëª…|ë§í¬|
|-|-|-|-|
23.02.17|íŒŒì´ì¬ ê¸°ì´ˆ|ë³€ìˆ˜ ë° í•¨ìˆ˜ ì„¤ëª…, parameter ê°œë…

### í•„ê¸°
+ ë³€ìˆ˜ => ë³€ìˆ˜ëª… = ë‚´ìš©
+ ë³€ìˆ˜ëª…ì—ëŠ” ë¹ˆê³µê°„ì´ ìˆìœ¼ë©´ ì•ˆë˜ë¯€ë¡œ camel case(myAge), snake case(my_age) ìŠ¤íƒ€ì¼ì„ ì£¼ë¡œ ì‚¬ìš©
+ ë³€ìˆ˜ëª…ì€ ìˆ«ì, íŠ¹ìˆ˜ë¬¸ìë¡œ ì‹œì‘í•˜ì§€ ì•ŠëŠ”ë‹¤.
+ " " => ë¬¸ìì—´
+ boolean => ì°¸(True) ë˜ëŠ” ê±°ì§“(False)
+ function => def í‘ì…˜ì´ë¦„():

### ì‹¤ìŠµ

~~~
def say_hello(name):
  print("hello",name, "how r u?")
say_hello("jg")

 #name => parameter
 #jg => argument
~~~

~~~
def multi(name, age):
 print("hello",name)
 print("you are", age, "years old") 
multi("jg", 23)

 #í•¨ìˆ˜ì˜ ê°¯ìˆ˜ì™€ ìˆœì„œì— ìœ ì˜
~~~

## íŒŒì´ì¬ ìŠ¤í„°ë”” 2ì¼ì°¨

|ë‚ ì§œ|ì œëª©|ì„¤ëª…|ë§í¬|
|-|-|-|-|
23.02.18|íŒŒì´ì¬ ê¸°ì´ˆ2|ë³µìŠµ, íŒŒë¼ë¯¸í„° ê¸°ë³¸ê°’ ì„¤ì •, ë¦¬í„´ë¬¸, ì¡°ê±´ë¬¸

### ë³µìŠµ
+ í•¨ìˆ˜ => ì‘ì„±í›„ ëª‡ë²ˆì´ê³  ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì½”ë“œ
+ íŒŒë¼ë¯¸í„° => í•¨ìˆ˜ ì•ˆìœ¼ë¡œ ë°ì´í„°ë¥¼ ë³´ë‚´ í•¨ìˆ˜ì˜ ê²°ê³¼ë¥¼ ë°”ê¿€ ìˆ˜ ìˆê²Œ í•˜ëŠ”ê²ƒ

### í•™ìŠµë‚´ìš© (ì‹¤ìŠµ í¬í•¨)

+ íŒŒë¼ë¯¸í„° ê¸°ë³¸ê°’ ì„¤ì •
~~~
def say_hello(name="anonymous"):
 print("hello", name)
say_hello()
~~~

+ ê³¼ì œ(ê³„ì‚°ê¸°)
~~~
def plus(a="0", b="0"):
  print(a + b)
plus(8, 2)
plus()
 # =10 (ë”í•˜ê¸°)

def minus(a="0", b="0"):
  print(a - b)
minus(8, 2)
 # =6 (ë¹¼ê¸°)

def mltp(a="0", b="0"):
  print(a * b)
mltp(8, 2)
 # =16 (ê³±í•˜ê¸°)

def dvsn(a="0", b="0"):
  print(a / b)
dvsn(8, 2)
 # =4 (ë‚˜ëˆ„ê¸°)

def pwo(a="0"):
  print(a**2)
pwo(8)
 # =64 (ì œê³±)
~~~


+ returnë¬¸: í•¨ìˆ˜ ë°”ê¹¥ìœ¼ë¡œ ê°’ì„ ë³´ë‚´ì¤Œ. ê·¸ë¦¬ê³  í•¨ìˆ˜ ì¢…ë£Œ
~~~
 #ì‹¤ìŠµ1(ì„¸ê¸ˆ ê³„ì‚°ê¸°)
def tax_calc(money):
 return money * 0.35

def pay_tax(tax):
  print("thank yo for paying", tax)
  
pay_tax(tax_calc(1500000))
 # ì‹¤ìŠµ ì„¤ëª…: tax_calcì˜ ë¦¬í„´ê°’ì„ ë°›ì•„ì„œ pay_taxì˜ í”„ë¦°íŠ¸ë¬¸ ìˆ˜í–‰
~~~

+ ë¬¸ìì—´ì— ë³€ìˆ˜ ì¶”ê°€í•˜ëŠ” ë²• => f "~~" { }
~~~
name = "jg"
age = 23
eyesclr = "black"

print(f"hello I'm {name}, i have {age} years in the earth, {eyesclr} is my eye color")
~~~

~~~
 #ì‹¤ìŠµ2(ì£¼ìŠ¤ë©”ì´ì»¤)-returnë¬¸, ë¬¸ìì—´ ë³€ìˆ˜ì¶”ê°€ë²• í™œìš©
def make_juice(fruit):
  return f"{fruit}+ğŸ¥¤"

def add_ice(juice):
  return f"{juice}+ğŸ§Š"

def add_sugar(iced_juice):
  return f"{iced_juice}+ğŸ­"

juice = make_juice("ğŸ")
cold_juice = add_ice(juice)
perfect_juice = add_sugar(cold_juice)
print(perfect_juice)

 #ì‹¤ìŠµ ì„¤ëª…
1) make_juiceë¥¼ í†µí•´ ì‚¬ìš©ìê°€ ì…ë ¥í•œ fruitê°€ fruit+ğŸ¥¤ ìœ¼ë¡œ ë¦¬í„´
2) add_iceë¥¼ í†µí•´ ë§Œë“¤ì–´ì§„ jucie ê°’ì— ğŸ§Šì´ í”ŒëŸ¬ìŠ¤ ë˜ì–´ juice+ğŸ§Šìœ¼ë¡œ ë¦¬í„´
3) add_sugarë¥¼ í†µí•´ ì–¼ìŒì´ ì¶”ê°€ëœ jucie (iced_juice)ì— ğŸ­ì´ í”ŒëŸ¬ìŠ¤ ë˜ì–´ iced_juice+ğŸ­ê°€ ë¦¬í„´
4) ë§ˆì§€ë§‰ ë„¤ì¤„ì€ 1~3ì„ ì°¨ë¡€ë¡œ ì‹¤í–‰ì‹œì¼œ ì¶œë ¥ì‹œí‚´ (ê²°ê³¼: ğŸ+ğŸ¥¤+ğŸ§Š+ğŸ­)
~~~

+ ifë¬¸ - ifë¬¸ì˜ ì¡°ê±´ì´ ì°¸ì´ë©´ ì½”ë“œ ì‹¤í–‰
  elseë¬¸ - ifë¬¸ì˜ ì¡°ê±´ì´ í‹€ë¦´ ì‹œ ì‹¤í–‰
  elifë¬¸ - ì—¬ëŸ¬ ì¡°ê±´ í™•ì¸ ì‹œ ì‚¬ìš©
  ì°¸ê³ : ifë¬¸ì˜ ì¡°ê±´ì´ ì°¸ì¼ì‹œ ê·¸ ë’¤ì˜ elif, else ë¬¸ì˜ ì¡°ê±´ë“¤ì€ í™•ì¸ì•ˆí•¨
~~~
 #ifë¬¸ ì‹¤ìŠµ
winner = 10

if winner > 10:
  print("winner is greater than 10")
  
elif winner < 10: #ifë¬¸ ì¡°ê±´ ì™¸ì— ë‹¤ë¥¸ ì¡°ê±´ í™•ì¸, ì¡°ê±´ì°¸ì´ë©´ ë’¤ì˜ ì¡°ê±´ë“¤ì€ í™•ì¸ì•ˆí•¨
  print("winner is less than 10")

else: #winner = 10, ëª¨ë“  ê²½ìš°ê°€ false ì¼ë•Œ
  print("winner is 10")
 #ê²°ê³¼: winner is 10 (winnerë³€ìˆ˜ê°€ 10ì´ë¯€ë¡œ ifë¬¸ê³¼ elifë¬¸ì€ ê±°ì§“, ë”°ë¼ì„œ elseë¬¸ ì‘ë™)
~~~



## íŒŒì´ì¬ ìŠ¤í„°ë”” 3ì¼ì°¨

### í•„ê¸°
+ input => í•˜ë‚˜ì˜ argumentë¥¼ ë°›ìŒ, ì‚¬ìš©ìì˜ ì…ë ¥ê°’ì´ ë¦¬í„´ê°’

+ type => ì…ë ¥ê°’ì˜ íƒ€ì… ì¶œë ¥
+ print(type(ì…ë ¥ê°’))

+ and => ë™ì‹œì— ë‘ ì¡°ê±´ì„ í™•ì¸, ëª¨ë‘ ì°¸ì´ì—¬ì•¼ë§Œ true
  true and true = true
  true and false = false
  false and true = false
  false and false = false

+ or => ì•ë¶€ë¶„ ë˜ëŠ” ë’·ë¶€ë¶„ì´ ì°¸ì¸ì§€ í™•ì¸(í•˜ë‚˜ë§Œ ì°¸ì´ì–´ë„ ë¨)
  true or true = true
  true or false = true
  false or true = true
  false or false = false

+ íŒŒì´ì¬ì—ëŠ” ë‹¤ì–‘í•œ í•¨ìˆ˜ë¥¼ í¬í•¨í•œ ëª¨ë“ˆì´ ìˆê³ , í•„ìš”ì‹œ ì´ë¥¼ importí•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤!

+ while => ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ ì½”ë“œë¥¼ ë¬´í•œíˆ ë°˜ë³µ

### ì‹¤ìŠµ
~~~
 #ì‹¤ìŠµ1(íŒŒì´ì¬ ì¹´ì§€ë…¸) 
from random import randint
print("welcome to python casino!")

pc_choice = randint(0, 100)

playing = True

while playing:
 
 user_choice = int(input("choose number(1~100).: "))

 if user_choice == pc_choice:
   print("you won!")
   playing = False

 elif user_choice > pc_choice:
   print("lower!")

 elif user_choice < pc_choice:
   print("higher!")
~~~


## íŒŒì´ì¬ ìŠ¤í„°ë”” 4ì¼ì°¨

### í•„ê¸° ë° ì‹¤ìŠµ

+ ë©”ì†Œë“œ => ë°ì´í„°ì™€ ê²°í•©ëœ function
+ ë°ì´í„°.ë©”ì†Œë“œëª…()
+ ë§¤ìš° ë‹¤ì–‘í•¨ [startswith(ì²«ê¸€ì í™•ì¸), endswith(ëê¸€ì í™•ì¸), replace(êµì²´), upper(ëŒ€ë¬¸ìë¡œ êµì²´),count(ìˆ˜ ì„¸ê¸°), clear(ë¦¬ìŠ¤íŠ¸ ë‚´ìš© ëª¨ë‘ ì‚­ì œ), append(ë¦¬ìŠ¤íŠ¸ì— ë‚´ìš© ì¶”ê°€) ë“±]
~~~
 #ì‹¤ìŠµ
name = "jg"
name.upper()
~~~

+ ë¦¬ìŠ¤íŠ¸ => ì´ë¦„=[ë‚´ìš©], ì–´ë–¤ í˜•ì‹ì´ë“  ë„£ì„ ìˆ˜ ìˆìŒ
~~~
days = ["mon", "tue", "wed"]
print(days[0])
~~~

+ íŠœí”Œ => ì´ë¦„(ë‚´ìš©), ë¦¬ìŠ¤íŠ¸ì™€ ë‹¤ë¥´ê²Œ ë¶ˆë³€ì„±ì„ ê°€ì§(ë³€ê²½ ë¶ˆê°€), ì•„ì´í…œì— ì ‘ê·¼í• ë• ëŒ€ê´„í˜¸ ì‚¬ìš©
~~~
days2 = ("mon", "tue", "wed")
print(days2[0])
~~~

+ dictionary => ì´ë¦„={ë‚´ìš©}, ì¸ë±ìŠ¤ë¥¼ ì¨ì•¼í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ì™€ëŠ” ë‹¤ë¥´ê²Œ í‚¤-ê°’ ìŒìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆê¸° ë•Œë¬¸ì— í‚¤ë¥¼ í†µí•´ ê°’ í˜¸ì¶œ ê°€ëŠ¥
~~~
player = {
    'name' : 'jg',
    'age' : 23,
    'alive' : True,
    'fav_food' : ['cola', 'apple']
}

print(player['age']) #player ë”•ì…”ë„ˆë¦¬ì˜ age ì¶œë ¥
player['fav_food'].append("noodle") #player ë”•ì…”ë„ˆë¦¬ì˜ fav_food ë¦¬ìŠ¤íŠ¸ì— noodle ì¶”ê°€
~~~


## íŒŒì´ì¬ ìŠ¤í„°ë”” 5ì¼ì°¨
### í•„ê¸° ë° ì‹¤ìŠµ

~~~
from requests import get

websites = (
    "https://google.com",
    "naver.com",
    "twitter.com",
    "facebook.com"
)

results={}

for website in websites: #ë¦¬ìŠ¤íŠ¸(íˆ¬í”Œ) ë‚´ ê° ì•„ì´í…œì— ëŒ€í•˜ì—¬ ì½”ë“œ ì‹¤í–‰
  if not website.startswith("https://"): #websiteê°€ https://ë¡œ ì‹œì‘í•˜ì§€ ì•Šìœ¼ë©´
   website = f"https://{website}" #websiteì— https://ë¥¼ ë¶™ì„
  # print(website)
  response = get(website) #getí•¨ìˆ˜ëŠ” ì›¹ì‚¬ì´íŠ¸ì˜ ì‘ë‹µì„ ë¦¬í„´
  if response.status_code == 200: #staus code => ê²°ê³¼ì—ì„œ ìƒíƒœ(ìˆ«ì)ë§Œ ë¦¬í„´í•¨
    results[website]  =  "ok" #ìƒˆë¡œìš´ í‚¤(í•´ë‹¹í•˜ëŠ” website)ë¥¼ results ë‹¥ì…”ë„ˆë¦¬ì— ì¶”ê°€, okë¼ê³  ì •ì˜(=)
  else:   
    results[website]  =  "failed"

print(results) 
~~~

+ ì°¸ê³ : PypiëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ì›¹ ì‚¬ì´íŠ¸ì´ë‹¤.


## íŒŒì´ì¬ ìŠ¤í„°ë”” 6ì¼ì°¨
### í•„ê¸° ë° ì‹¤ìŠµ

~~~
from requests import get
from bs4 import BeautifulSoup #beatifulsoup => ì›¹ì‚¬ì´íŠ¸(html)ì˜ ë°ì´í„°ë¥¼ ë°›ì•„ì˜¬ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬

base_url = "https://weworkremotely.com/remote-jobs/search?utf8=âœ“&term="
search_term = "python"

response = get(f"{base_url}{search_term}") #ì£¼ì†Œ(base_url + search_term)ì˜ ì‘ë‹µì„ ë°›ì•„ì˜´

if response.status_code != 200:
    print("can't request website")

else:
    soup = BeautifulSoup(response.text, "html.parser") # html.parser => htmlì„ ë³´ë‚´ì¤€ë‹¤ê³  beatifulsoupì— ì „ë‹¬
    jobs = soup.find_all('section', class_="jobs")
     #section(ì§ì—… ì „ì²´) => li(ì§ì—… ê¸°ì—…ë³„ë¡œ ë¶„ë¥˜) => anchor(ì§ì—… ì •ë³´)
     #section ì¤‘ classê°€ jobsì¸ sectionì˜ ë‚´ìš©ì„ ê°€ì ¸ì˜´
     #class_="jobs" => keyword argument(ìˆœì„œ(ìœ„ì¹˜)ë¥¼ ì‹ ê²½ ì“°ì§€ ì•ŠëŠ” ê²½ìš°)
    for job_section in jobs:
        job_posts = job_section.find_all("li") #ëª¨ë“  li(ì§ì—… ë¦¬ìŠ¤íŠ¸)ë¥¼ ì°¾ì•„ëƒ„
        job_posts.pop(-1) #job listì—ì„œ ë§ˆì§€ë§‰ í•­ëª© ì œê±°(view all ë²„íŠ¼ì´ ì¶œë ¥ë˜ì§€ ì•Šë„ë¡ í•¨)
        for post in job_posts: #job postsì—ì„œ anchorsë¥¼ ì¶”ì¶œí•˜ê³ , anchorsì—ì„œ href ì €ì¥ ë° companyê°€ ë“¤ì–´ê°„ span(ì„¸ë¶€ ì •ë³´)ë¥¼ ì¶”ì¶œ(li ìˆ˜ëŒ€ë¡œ ë°˜ë³µ)
            anchors = post.find_all('a') #job_postsì—ì„œ anchorë¥¼ ì°¾ì•„ëƒ„
            anchor = anchors[1] #ë‘ë²ˆì§¸ anchorê°€ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— ë‘ë²ˆì§¸ í•­ëª©ì„ ë‹¬ë¼ê³  ìš”ì²­
            link = anchor['href']
            company, kind, region = anchor.find_all('span', class_="company") #span í´ë˜ìŠ¤ ì¤‘ companyê°€ ë“¤ì–´ê°„ í´ë˜ìŠ¤ë¥¼ ì°¨ë¡€ë¡œ ì¶”ì¶œ
            title = anchor.find('span', class_ = 'title')
            print(company, kind, region, title)
            print("/////////////////")
            print("/////////////////")
~~~

## íŒŒì´ì¬ ìŠ¤í„°ë”” 7ì¼ì°¨
### í•„ê¸° ë° ì‹¤ìŠµ

+ weworkremotelyìš© ì›¹ìŠ¤í¬ë˜í¼ ì™„ì„±
  1. ì •ë³´ ì €ì¥ ë° í•¨ìˆ˜í™”
~~~
from requests import get
from bs4 import BeautifulSoup #beatifulsoup => ì›¹ì‚¬ì´íŠ¸(html)ì˜ ë°ì´í„°ë¥¼ ë°›ì•„ì˜¬ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬

def extract_jobs(keyword):
  base_url = "https://weworkremotely.com/remote-jobs/search?utf8=âœ“&term="
  keyword

  response = get(f"{base_url}{keyword}") #ì£¼ì†Œ(base_url + keyword)ì˜ ì‘ë‹µì„ ë°›ì•„ì˜´

  if response.status_code != 200:
    print("can't request website")

  else:
    results = []
    soup = BeautifulSoup(response.text, "html.parser") # html.parser => htmlì„ ë³´ë‚´ì¤€ë‹¤ê³  beatifulsoupì— ì „ë‹¬, response.text => ì›¹ì‚¬ì´íŠ¸ì˜ ì½”ë“œ, beatifulsoup => response.textë¥¼ ë°›ì•„ì™€ì„œ pythonì˜ ë°ì´í„° êµ¬ì¡°ë¡œ ë³€í™˜
    jobs = soup.find_all('section', class_="jobs") #section(ì§ì—… ì „ì²´) => li(ì§ì—… ê¸°ì—…ë³„ë¡œ ë¶„ë¥˜) => anchor(ì§ì—… ì •ë³´)
                                                   #section ì¤‘ classê°€ jobsì¸ sectionì˜ ë‚´ìš©ì„ ê°€ì ¸ì˜´
                                                   #class_="jobs" => keyword argument(ìˆœì„œ(ìœ„ì¹˜)ë¥¼ ì‹ ê²½ ì“°ì§€ ì•ŠëŠ” ê²½ìš°)
    for job_section in jobs:
        job_posts = job_section.find_all("li") #ëª¨ë“  li(ì§ì—… ë¦¬ìŠ¤íŠ¸)ë¥¼ ì°¾ì•„ëƒ„
        job_posts.pop(-1) #job listì—ì„œ ë§ˆì§€ë§‰ í•­ëª© ì œê±°(view all ë²„íŠ¼ì´ ì¶œë ¥ë˜ì§€ ì•Šë„ë¡ í•¨)
        for post in job_posts: #job postsì—ì„œ anchorsë¥¼ ì¶”ì¶œí•˜ê³ , anchorsì—ì„œ href ì €ì¥ ë° companyê°€ ë“¤ì–´ê°„ span(ì„¸ë¶€ ì •ë³´)ë¥¼ ì¶”ì¶œ(li ìˆ˜ëŒ€ë¡œ ë°˜ë³µ)
            anchors = post.find_all('a') #job_postsì—ì„œ anchorë¥¼ ì°¾ì•„ëƒ„
            anchor = anchors[1] #ë‘ë²ˆì§¸ anchorê°€ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— ë‘ë²ˆì§¸ í•­ëª©ì„ ë‹¬ë¼ê³  ìš”ì²­
            link = anchor['href']
            company, kind, region = anchor.find_all('span', class_="company") #span í´ë˜ìŠ¤ ì¤‘ companyê°€ ë“¤ì–´ê°„ í´ë˜ìŠ¤ë¥¼ ì°¨ë¡€ë¡œ ì¶”ì¶œ
            title = anchor.find('span', class_ = 'title')
            job_data = {  #ê¸€ìë§Œì„ ì¶”ì¶œí•˜ì—¬ job_data ë”•ì…”ë„ˆë¦¬ì— ì €ì¥
                'link': f"https://weworkremotely.com/{link}",
                'company': company.string,
                'region': region.string,
                'position': title.string
            }
            results.append(job_data)
    for result in results:
        return results     
~~~

 2. í•¨ìˆ˜ ì‚¬ìš©
 ~~~
 from requests import get
 from bs4 import BeautifulSoup 
 from extractors.study6 import extract_jobs

 jobs = extract_jobs("python") #ê²€ìƒ‰í•˜ê³ ì í•˜ëŠ” ë‹¨ì–´ ì…ë ¥
 print(jobs)
 ~~~

+ indeedìš© ì›¹ìŠ¤í¬ë˜í¼

~~~
from bs4 import BeautifulSoup
from selenium import webdriver #ì…€ë ˆë‹ˆì›€
from selenium.webdriver.chrome.options import Options

options = Options()
options.add_experimental_option("detach", True)

browser = webdriver.Chrome(options=options)
browser.get("http://www.indeed.com/jobs?q=python&limit=50")

soup = BeautifulSoup(browser.page_source, "html.parser")
job_list = soup.find("ul", class_="jobsearch-ResultsList")
jobs = job_list.find_all('li', recursive=False) #recursive=False => ul ë°”ë¡œ ì•„ë˜ì˜ Lië§Œ ì°¾ê¸° ìœ„í•´ì„œ
for job in jobs:
    zone = job.find("div", class_ = "mosaic-zone")

    if zone == None: #ì§ì—… ì •ë³´ë¥¼ li ì•ˆì— ìˆë‹¤ë©´ (NONE => ë¬´ì–¸ê°€ ì—†ì„ ë•Œ))
     print("job li")
~~~


## íŒŒì´ì¬ ìŠ¤í„°ë”” 8ì¼ì°¨
### í•„ê¸° ë° ì‹¤ìŠµ

+ indeedë¥¼ í™œìš©í•œ ì›¹ìŠ¤í¬ë˜í¼ ì œì‘ ì™„ë£Œ ë° í•¨ìˆ˜ ì •ì˜

~~~

from bs4 import BeautifulSoup
from selenium import webdriver #ì…€ë ˆë‹ˆì›€
from selenium.webdriver.chrome.options import Options

def get_page_count(keyword): #í˜ì´ì§€ ìˆ˜ ì„¸ê¸°(ìŠ¤í¬ë˜í•‘ í•´ì•¼í•  í˜ì´ì§€ ìˆ˜ ì„¸ê¸°)
    options = Options()
    options.add_experimental_option("detach", True)
    response = webdriver.Chrome(options=options)

    base_url = "https://www.indeed.com/jobs?q="
    response.get(f"{base_url}{keyword}")


    soup = BeautifulSoup(response.page_source, "html.parser")
    pagination = soup.find("ul", class_ = "pagination-list")

    if pagination == None:
        return 1 #paginationì´ Noneì´ë©´(í˜ì´ì§€ê°€ í•˜ë‚˜ë°–ì— ì—†ìœ¼ë©´) 1ì„ ë¦¬í„´
    
    pages = pagination.find("li", recursive=False)

    count = len(pages)

    if count >= 5:
        return 5
    
    else:
        return count
    
-------------------------------------------------------------------

def extract_indeed_jobs(keyword): #í˜ì´ì§€ ë³„ë¡œ ì§ì—…ì •ë³´ ìŠ¤í¬ë˜í•‘ì„ ë°˜ë³µ 
    pages = get_page_count(keyword)
    print("Found", pages, "pages")
    results = []
    for page in range(pages): #range => ìˆœì„œ ê°ì²´ë¥¼ ë¦¬í„´í•´ì£¼ëŠ” í•¨ìˆ˜(ì¦‰ì‹œ Listë¥¼ ìƒì„±)

        options = Options()
        options.add_experimental_option("detach", True)
        response = webdriver.Chrome(options=options)
        
        base_url = "https://www.indeed.com/jobs"
        final_url = f"{base_url}?q={keyword}&start={page*10}"
        print("Requesting", final_url)
        response.get(final_url)

        soup = BeautifulSoup(response.page_source, "html.parser")
        job_list = soup.find("ul", class_="jobsearch-ResultsList")
        jobs = job_list.find_all('li', recursive=False) #recursive=False => ul ë°”ë¡œ ì•„ë˜ì˜ Lië§Œ ì°¾ê¸° ìœ„í•´ì„œ
        for job in jobs:
            zone = job.find("div", class_ = "mosaic-zone")

            if zone == None: #ì§ì—… ì •ë³´ë¥¼ li ì•ˆì— ìˆë‹¤ë©´ (NONE => ë¬´ì–¸ê°€ ì—†ì„ ë•Œ))
                    #  h2 = job.find("h2", class_="jobTitle") 
                    #  a = h2.find("a")
                anchor = job.select_one("h2 a") #h2ë¥¼ ì„ íƒí•˜ì—¬ ë“¤ì–´ê°„ ë‹¤ìŒ, aë¥¼ ê°€ì§„ ë¦¬ìŠ¤íŠ¸ í•˜ë‚˜ë§Œ ê°€ì ¸ì™€ë¼.
                title = anchor['aria-label']
                link = anchor['href']
                company = job.find("span", class_="companyName")
                location = job.find("div", class_="companyLocation")

                job_data = {
                    'link': f"https://www.indeed.com{link}",
                    'company': company.string,
                    'location': location.string,
                    "postion": "" #aria label
                    }
                results.append(job_data)
    return results
~~~


## íŒŒì´ì¬ ìŠ¤í„°ë”” 9ì¼ì°¨
### í•„ê¸° ë° ì‹¤ìŠµ
~~~
 #ë§Œë“¤ì—ˆë˜ í•¨ìˆ˜ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ ì €ì¥í•˜ê¸°

from requests import get
from bs4 import BeautifulSoup
from selenium.webdriver.chrome.options import Options
from extractors.study7 import extract_indeed_jobs
from extractors.study6 import extract_jobs

keyword = input("what do you want to search for?")

indeed = extract_indeed_jobs(keyword)
extj = extract_jobs(keyword)

jobs = indeed + extj

def save_to_file(file_name, jobs):

    file = open(f"{file_name}.csv", "w") #csvë¡œ(ì…ë ¥ëœ keywordë¥¼ ì œëª©ìœ¼ë¡œ) ì €ì¥(ì“°ê¸° ì „ìš©ìœ¼ë¡œ) => ì´ë¦„ê³¼ ëª¨ë“œ ì„¤ì •
    file.write("Position, Company, Location, URL\n") #Position, Company, Location, URLì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì—´ë§ˆë‹¤ ì‚½ì… í›„ ì¤„ë°”ê¿ˆ
    for job in jobs:
        file.write(f"{job['position']}, {job['company']}, {job['location']},{job['link']}\n") # ìŠ¤í¬ë©í•œ ì •ë³´(Position, Company, Location, URL)ë¥¼ ì—´ë§ˆë‹¤ ì‚½ì… í›„ ì¤„ë°”ê¿ˆ

    file.close()
~~~

## íŒŒì´ì¬ ìŠ¤í„°ë”” 10ì¼ì°¨
### í•„ê¸° ë° ì‹¤ìŠµ

+ flask ê¸°ë³¸ ë° ì‹¤ìŠµ
~~~
 #flask => íŒŒì´ì¬ì„ ì´ìš©í•´ì„œ ì›¹ì‚¬ì´íŠ¸ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆëŠ” ì´ˆì†Œí˜• í”„ë ˆì„ì›Œí¬

from flask import Flask, render_template

app = Flask("jobscrapper")

@app.route("/")
def home():
    return render_template("home.html")

@app.route("/search")
def hello():
    return render_template("search.html")


app.run("127.0.0.1")
~~~

+ html ë‹¤ë£¨ê¸°(ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©)
~~~
<!DOCTYPE html>
<html lang="en">
<head>
 <meta charset="UTF-8">
 <meta http-equiv="X-UA-Compatible" contents="IE=edge">
 <meta name="viewport" content="width=device-width,
 initial-scale=1.0">
 <title>job scrapper</title>

</head>
<body>
<h1>Search Results:</h1>
<h4>What job do you want?</h4>
<form action="/search"> 
    <input type = "text" name = "keyword" placeholder = "Write keyword please" />
    <button>Search</button>
</form>
</body>
</html>
~~~

## íŒŒì´ì¬ ìŠ¤í„°ë”” 11ì¼ì°¨
### í•„ê¸° ë° ì‹¤ìŠµ

+ main.py ë¶€ë¶„(exract_indeed_jobs, extract_jobs í•¨ìˆ˜ë¥¼ ì¶”ê°€í•˜ì—¬ ì§ì—…ì •ë³´ ë°›ì•„ì˜¤ë„ë¡ í•¨)
~~~
from flask import Flask, render_template, request
from extractors.study7 import extract_indeed_jobs
from extractors.study6 import extract_jobs

app = Flask("jobscrapper")

@app.route("/")
def home():
    return render_template("home.html", name = "jg")

@app.route("/")
def search():
    keyword = request.args.get("keyword")
    indeed = extract_indeed_jobs(keyword)
    ijs = extract_jobs(keyword)
    jobs = indeed + ijs
    return render_template("search.html", keyword=keyword, jobs=jobs)

app.run("127.0.0.1")
~~~

+ serach.html ë¶€ë¶„(ë°›ì•„ì˜¨ ì§ì—…ì •ë³´ë¥¼ ë„ìš°ëŠ” ê¸°ëŠ¥ ì¶”ê°€)
 í•„ê¸°
 1) flaskì—ì„œ forë¬¸ì„ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ => {% for~~ %} RmxsofEosms {% endfor %}
 2) {{}} ë¬¸ë²•ê³¼ {%%}ë¬¸ë²•ì˜ ì°¨ì´ => {{}}ì•ˆì— ë³€ìˆ˜ë¥¼ ë„£ìœ¼ë©´  flsakê°€ ë³€ìˆ˜ë¥¼ ê°’ìœ¼ë¡œ ë³€í™˜, {%%}ì€ ì‹¤í–‰í•˜ê³ ì í•˜ëŠ” íŒŒì´ì¬ ì½”ë“œë¥¼ ì…ë ¥
 3) ì½”ë“œì— ìˆëŠ” forë¬¸ ì„¤ëª… => flaskê°€ {{}}ì•ˆì— ìˆëŠ” ê±¸(position, company ë“±) ë°ì´í„°ë¡œ ë³€í™˜
~~~
<!DOCTYPE html>
<html lang="en">
<head>
 <meta charset="UTF-8">
 <meta http-equiv="X-UA-Compatible" contents="IE=edge">
 <meta name="viewport" content="width=device-width,
 initial-scale=1.0">
 <title>job scrapper</title>

</head>
<body>
<h1>Search Results for "{{keyword}}":</h1>

{% for job in jobs %} 
<div>
    <span>{{job.position}}</span>
    <span>{{job.company</span>
    <span>{{job.location}}</span>
    <a href = "{{job.link}}" target = "_blank">Apply now &rarr;</a>
</div>
{% endfor %}

<h4>What job do you want?</h4>
<form action="/search"> 
    <input type = "text" name = "keyword" placeholder = "Write keyword please" />
    <button>Search</button>
</form>
</body>
</html>
~~~

## íŒŒì´ì¬ ìŠ¤í„°ë”” 12ì¼ì°¨
### í•„ê¸° ë° ì‹¤ìŠµ

+ main.py(íŒŒì¼ ë‹¤ìš´ ê¸°ëŠ¥ ì¶”ê°€)
~~~
from flask import Flask, render_template, request, redirect, send_file
from extractors.study7 import extract_indeed_jobs
from extractors.study6 import extract_jobs
from study7_1 import save_to_file
app = Flask("JobScrapper")

db = {}

@app.route("/")
def home():
    return render_template("home.html")

@app.route("/search")
def search():
    keyword = request.args.get("keyword")
    if keyword == None: #ì•„ë¬´ê²ƒë„ ê²€ìƒ‰í•˜ì§€ ì•Šì•˜ì„ ë•Œ
       return redirect("/") #ë‹¤ì‹œ ëŒë ¤ë³´ëƒ„
    if keyword in db:
     jobs = db[keyword]
    else:
        indeed = extract_indeed_jobs(keyword)
        ijs = extract_jobs(keyword)
        jobs = indeed + ijs
        db[keyword] = jobs
    return render_template("search.html", keyword=keyword, jobs=jobs)

@app.route("/export")
def export():
   keyword = request.args.get("keyword")
   if keyword == None:
      return redirect("/")
   if keyword not in db:
      return redirect(f"/search?keyword={keyword}")
   save_to_file(keyword, db[keyword]) #íŒŒì¼ ì €ì¥
   return send_file(f"{keyword}.csv", as_attachment=True)

app.run("0.0.0.0")
~~~

+ home.html(pico, tableì„ í™œìš©í•˜ì—¬ ì´ì˜ê²Œ ë§Œë“¤ê¸°)
~~~
<!DOCTYPE html>
<html lang="en">

<head>
 <meta charset="UTF-8">
 <meta http-equiv="X-UA-Compatible" contents="IE=edge">
 <meta name="viewport" content="width=device-width, initial-scale=1.0">
 <title>job scrapper</title>
 <link rel="stylesheet" href="https://unpkg.com/@picocss/pico@1.*/css/pico.min.css">
</head>

<body>
 <main class = "container">
    <h1>Job Scrapper</h1>
    <h4>What job do you want?</h4>
    <form action="/search" method="get">
        <input type = "text" name = "keyword" placeholder = "Write keyword please" />
        <button>Search</button>
    </form>>
 </main>
</body>

</html>
~~~

+ search.html(pico, tableì„ í™œìš©í•˜ì—¬ ì´ì˜ê²Œ ë§Œë“¤ê¸°)
~~~
<!DOCTYPE html>
<html lang="en">

<head>
 <meta charset="UTF-8">
 <meta http-equiv="X-UA-Compatible" contents="IE=edge">
 <meta name="viewport" content="width=device-width, initial-scale=1.0">
 <title>Job Scrapper</title>
 <link rel="stylesheet" href="https://unpkg.com/@picocss/pico@1.*/css/pico.min.css">
</head>

<body>
    <main class = "container">    
        <hgroup>
         <h1>Search Results for "{{keyword}}":</h1>
         <a target="_blank" href="/export?keyword={{keyword}}">Export to file</a>"
         <a target="_blank" href="/">Go to home</a>
        </hgroup>

        <table role = "grid">
            <thread>
                <tr>
                    <th>Position</th>
                    <th>Company</th>
                    <th>Location</th>
                    <th>Link</th>
                </tr>
            </thread>

            <tbody>
            {% for job in jobs %} 
                <tr>
                    <td>{{job.position}}</td>
                    <td>{{job.company}}</td>
                    <td>{{job.location}}</td>
                    <td><a href = "{{job.link}}" target = "_blank">Apply &rarr;</a></td>
                </tr>
            {% endfor %}  
            </tbody>
            <figure></figure>
        </table>
    </main>
</body>

</html>
~~~